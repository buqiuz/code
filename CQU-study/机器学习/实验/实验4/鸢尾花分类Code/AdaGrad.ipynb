{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9cf4a3d-8302-4e2c-9eaa-b17324c7f318",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''--------------------导入MindSpore模块和辅助模块--------------------'''\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "from matplotlib import pyplot as plt\n",
    "import mindspore\n",
    "from mindspore import nn\n",
    "from mindspore import context\n",
    "from mindspore import dataset\n",
    "from mindspore.train.callback import TimeMonitor, LossMonitor\n",
    "from mindspore import Tensor\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig # 回调机制\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"Ascend\") # 设定运行模式为静态图模式，并且运行设备为昇腾芯片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2dd471a-b25f-404d-8f37-d89c6e58ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''--------------------模型参数设置--------------------'''\n",
    "cfg = edict({\n",
    "    'data_size': 150,\n",
    "    'train_size': 120, #训练集大小\n",
    "    'test_size': 30 , #测试集大小\n",
    "    'feature_number': 4, #输入特征数\n",
    "    'num_class': 3, #分类类别\n",
    "    'batch_size': 30, #批次大小\n",
    "    'data_dir': 'iris.data', # 数据集路径\n",
    "    'save_checkpoint_steps': 5, #多少步保存一次模型\n",
    "    'keep_checkpoint_max': 1, #最多保存多少个模型\n",
    "    'out_dir_no_opt': './model_iris/no_opt', #保存模型路径，无优化器模型\n",
    "    'out_dir_sgd': './model_iris/sgd', #保存模型路径,SGD优化器模型\n",
    "    'out_dir_momentum': './model_iris/momentum', #保存模型路径，momentum模型\n",
    "    'out_dir_adam': './model_iris/adam', #保存模型路径，adam优化器模型\n",
    "    'output_prefix': \"checkpoint_fashion_forward\" #保存模型文件名\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73c206a6-a61a-40da-846b-cf7206d1e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''--------------------读取数据并根据MindSpore模型需求进行预处理--------------------\n",
    "共150条数据,将数据集的4个属性作为自变量X,3个类别映射为{0,1,2},作为因变量Y。'''\n",
    "#鸢尾花数据集，本数据集共有150个带标签的数据\n",
    "with open(cfg.data_dir) as csv_file:\n",
    "    data = list(csv.reader(csv_file, delimiter=','))\n",
    "\n",
    "label_map = {'setosa': 0,'versicolor': 1,'virginica':2 }\n",
    "#分别获取数据中的特征值X和标签值Y\n",
    "X = np.array([[float(x) for x in s[:-1]] for s in data[:cfg.data_size]],np.float32)\n",
    "Y = np.array([label_map[s[-1]] for s in data[:cfg.data_size]], np.int32)\n",
    "\n",
    "# 将数据集分为训练集120条，测试集30条。\n",
    "train_idx = np.random.choice(cfg.data_size, cfg.train_size, replace=False)\n",
    "test_idx = np.array(list(set(range(cfg.data_size)) - set(train_idx)))\n",
    "\n",
    "X_train, Y_train = X[train_idx], Y[train_idx]\n",
    "X_test, Y_test = X[test_idx], Y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fe2f7c0-9b9b-4b17-a2ba-8f4b9dbfc84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''--------------------使用MindSpore GeneratorDataset接口将numpy.ndarray类型的数据转换为Dataset--------------------'''\n",
    "XY_train = list(zip(X_train, Y_train))\n",
    "train_dataset = dataset.GeneratorDataset(XY_train, ['x', 'y'])\n",
    "train_dataset = train_dataset.shuffle(buffer_size=cfg.train_size).batch(cfg.batch_size, drop_remainder=True)\n",
    "XY_test = list(zip(X_test, Y_test))\n",
    "test_dataset = dataset.GeneratorDataset(XY_test, ['x', 'y'])\n",
    "test_dataset = test_dataset.shuffle(buffer_size=cfg.test_size).batch(cfg.test_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3055b0a0-d7b0-4f98-9bdb-ca0719cffac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------AdaGrad优化器--------------------\n",
      "==========Start Training==========\n",
      "epoch: 10 step: 4, loss is 0.952395498752594\n",
      "epoch: 20 step: 4, loss is 0.9048925638198853\n",
      "epoch: 30 step: 4, loss is 0.8587584495544434\n",
      "epoch: 40 step: 4, loss is 0.8136087656021118\n",
      "epoch: 50 step: 4, loss is 0.8160627484321594\n",
      "epoch: 60 step: 4, loss is 0.7633775472640991\n",
      "epoch: 70 step: 4, loss is 0.7553449869155884\n",
      "epoch: 80 step: 4, loss is 0.7327425479888916\n",
      "epoch: 90 step: 4, loss is 0.7070237398147583\n",
      "epoch: 100 step: 4, loss is 0.6870630979537964\n",
      "epoch: 110 step: 4, loss is 0.648048996925354\n",
      "epoch: 120 step: 4, loss is 0.6949187517166138\n",
      "epoch: 130 step: 4, loss is 0.685905396938324\n",
      "epoch: 140 step: 4, loss is 0.6803897023200989\n",
      "epoch: 150 step: 4, loss is 0.6800992488861084\n",
      "epoch: 160 step: 4, loss is 0.6193722486495972\n",
      "epoch: 170 step: 4, loss is 0.6015564203262329\n",
      "epoch: 180 step: 4, loss is 0.6505138874053955\n",
      "epoch: 190 step: 4, loss is 0.5875027179718018\n",
      "epoch: 200 step: 4, loss is 0.6157764792442322\n",
      "epoch: 210 step: 4, loss is 0.6002215147018433\n",
      "epoch: 220 step: 4, loss is 0.620162844657898\n",
      "epoch: 230 step: 4, loss is 0.5983875393867493\n",
      "epoch: 240 step: 4, loss is 0.5656222105026245\n",
      "epoch: 250 step: 4, loss is 0.6466796398162842\n",
      "epoch: 260 step: 4, loss is 0.6231023073196411\n",
      "epoch: 270 step: 4, loss is 0.5876328945159912\n",
      "epoch: 280 step: 4, loss is 0.6283359527587891\n",
      "epoch: 290 step: 4, loss is 0.5785468816757202\n",
      "epoch: 300 step: 4, loss is 0.5665704011917114\n",
      "epoch: 310 step: 4, loss is 0.5871766805648804\n",
      "epoch: 320 step: 4, loss is 0.5869766473770142\n",
      "epoch: 330 step: 4, loss is 0.6041580438613892\n",
      "epoch: 340 step: 4, loss is 0.5616515278816223\n",
      "epoch: 350 step: 4, loss is 0.48946070671081543\n",
      "epoch: 360 step: 4, loss is 0.48022985458374023\n",
      "epoch: 370 step: 4, loss is 0.5379385352134705\n",
      "epoch: 380 step: 4, loss is 0.525949239730835\n",
      "epoch: 390 step: 4, loss is 0.5643753409385681\n",
      "epoch: 400 step: 4, loss is 0.5167334079742432\n",
      "epoch: 410 step: 4, loss is 0.5838838815689087\n",
      "epoch: 420 step: 4, loss is 0.4555177092552185\n",
      "epoch: 430 step: 4, loss is 0.5388951301574707\n",
      "epoch: 440 step: 4, loss is 0.6233687400817871\n",
      "epoch: 450 step: 4, loss is 0.47108474373817444\n",
      "epoch: 460 step: 4, loss is 0.5513144135475159\n",
      "epoch: 470 step: 4, loss is 0.6138071417808533\n",
      "epoch: 480 step: 4, loss is 0.42577874660491943\n",
      "epoch: 490 step: 4, loss is 0.5155019760131836\n",
      "epoch: 500 step: 4, loss is 0.47457101941108704\n",
      "epoch: 510 step: 4, loss is 0.5136652588844299\n",
      "epoch: 520 step: 4, loss is 0.5099875926971436\n",
      "epoch: 530 step: 4, loss is 0.5180597305297852\n",
      "epoch: 540 step: 4, loss is 0.5662800073623657\n",
      "epoch: 550 step: 4, loss is 0.5143343806266785\n",
      "epoch: 560 step: 4, loss is 0.4749382734298706\n",
      "epoch: 570 step: 4, loss is 0.5387039184570312\n",
      "epoch: 580 step: 4, loss is 0.40835073590278625\n",
      "epoch: 590 step: 4, loss is 0.5205102562904358\n",
      "epoch: 600 step: 4, loss is 0.5192598700523376\n",
      "epoch: 610 step: 4, loss is 0.5025118589401245\n",
      "epoch: 620 step: 4, loss is 0.4803157150745392\n",
      "epoch: 630 step: 4, loss is 0.49551892280578613\n",
      "epoch: 640 step: 4, loss is 0.3982982933521271\n",
      "epoch: 650 step: 4, loss is 0.5237387418746948\n",
      "epoch: 660 step: 4, loss is 0.49522221088409424\n",
      "epoch: 670 step: 4, loss is 0.4184507727622986\n",
      "epoch: 680 step: 4, loss is 0.4996330738067627\n",
      "epoch: 690 step: 4, loss is 0.44723454117774963\n",
      "epoch: 700 step: 4, loss is 0.47812098264694214\n",
      "epoch: 710 step: 4, loss is 0.4934742748737335\n",
      "epoch: 720 step: 4, loss is 0.42780834436416626\n",
      "epoch: 730 step: 4, loss is 0.534842848777771\n",
      "epoch: 740 step: 4, loss is 0.408616840839386\n",
      "epoch: 750 step: 4, loss is 0.4500257074832916\n",
      "epoch: 760 step: 4, loss is 0.4732896089553833\n",
      "epoch: 770 step: 4, loss is 0.4341970682144165\n",
      "epoch: 780 step: 4, loss is 0.4692766070365906\n",
      "epoch: 790 step: 4, loss is 0.43344300985336304\n",
      "epoch: 800 step: 4, loss is 0.41848501563072205\n",
      "epoch: 810 step: 4, loss is 0.4700314998626709\n",
      "epoch: 820 step: 4, loss is 0.4495777487754822\n",
      "epoch: 830 step: 4, loss is 0.45152202248573303\n",
      "epoch: 840 step: 4, loss is 0.5109573602676392\n",
      "epoch: 850 step: 4, loss is 0.42083775997161865\n",
      "epoch: 860 step: 4, loss is 0.4422699213027954\n",
      "epoch: 870 step: 4, loss is 0.5199762582778931\n",
      "epoch: 880 step: 4, loss is 0.47371798753738403\n",
      "epoch: 890 step: 4, loss is 0.42314910888671875\n",
      "epoch: 900 step: 4, loss is 0.3915535807609558\n",
      "epoch: 910 step: 4, loss is 0.37471237778663635\n",
      "epoch: 920 step: 4, loss is 0.3044567108154297\n",
      "epoch: 930 step: 4, loss is 0.46507418155670166\n",
      "epoch: 940 step: 4, loss is 0.5047156810760498\n",
      "epoch: 950 step: 4, loss is 0.43885642290115356\n",
      "epoch: 960 step: 4, loss is 0.45899897813796997\n",
      "epoch: 970 step: 4, loss is 0.4229278564453125\n",
      "epoch: 980 step: 4, loss is 0.4332970976829529\n",
      "epoch: 990 step: 4, loss is 0.38534319400787354\n",
      "epoch: 1000 step: 4, loss is 0.3769336938858032\n",
      "{'Acc': 1.0}\n",
      "第0个sample预测结果： Versicolor     真实结果： Versicolor\n",
      "第1个sample预测结果： Virginica     真实结果： Virginica\n",
      "第2个sample预测结果： Setosa     真实结果： Setosa\n",
      "第3个sample预测结果： Versicolor     真实结果： Versicolor\n",
      "第4个sample预测结果： Virginica     真实结果： Virginica\n",
      "第5个sample预测结果： Virginica     真实结果： Virginica\n",
      "第6个sample预测结果： Virginica     真实结果： Virginica\n",
      "第7个sample预测结果： Setosa     真实结果： Setosa\n",
      "第8个sample预测结果： Setosa     真实结果： Setosa\n",
      "第9个sample预测结果： Virginica     真实结果： Virginica\n",
      "第10个sample预测结果： Setosa     真实结果： Setosa\n",
      "第11个sample预测结果： Versicolor     真实结果： Versicolor\n",
      "第12个sample预测结果： Versicolor     真实结果： Versicolor\n",
      "第13个sample预测结果： Versicolor     真实结果： Versicolor\n",
      "第14个sample预测结果： Setosa     真实结果： Setosa\n",
      "第15个sample预测结果： Setosa     真实结果： Setosa\n",
      "第16个sample预测结果： Setosa     真实结果： Setosa\n",
      "第17个sample预测结果： Setosa     真实结果： Setosa\n",
      "第18个sample预测结果： Setosa     真实结果： Setosa\n",
      "第19个sample预测结果： Versicolor     真实结果： Versicolor\n",
      "第20个sample预测结果： Virginica     真实结果： Virginica\n",
      "第21个sample预测结果： Versicolor     真实结果： Versicolor\n",
      "第22个sample预测结果： Virginica     真实结果： Virginica\n",
      "第23个sample预测结果： Setosa     真实结果： Setosa\n",
      "第24个sample预测结果： Virginica     真实结果： Virginica\n",
      "第25个sample预测结果： Versicolor     真实结果： Versicolor\n",
      "第26个sample预测结果： Versicolor     真实结果： Versicolor\n",
      "第27个sample预测结果： Setosa     真实结果： Setosa\n",
      "第28个sample预测结果： Versicolor     真实结果： Versicolor\n",
      "第29个sample预测结果： Setosa     真实结果： Setosa\n"
     ]
    }
   ],
   "source": [
    "'''--------------------AdaGrad优化器--------------------'''\n",
    "#定义神经网络、优化器和损失函数供模型Model使用\n",
    "Network = nn.Dense(cfg.feature_number, cfg.num_class)\n",
    "net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\n",
    "optimizer=nn.Adagrad(Network.trainable_params(),learning_rate=0.01)\n",
    "#调用模型Model，使用优化器，评价函数采用准确率\n",
    "model = Model(network=Network, loss_fn=net_loss, optimizer=optimizer, metrics={\"Acc\":nn.Accuracy()})\n",
    "\n",
    "# 定义回调类用来输出训练过程的信息\n",
    "config_ck = CheckpointConfig(save_checkpoint_steps=cfg.save_checkpoint_steps,keep_checkpoint_max=cfg.keep_checkpoint_max)\n",
    "ckpt_cb = ModelCheckpoint(prefix=\"checkpoint_no_opt\", directory= cfg.out_dir_no_opt, config=config_ck)\n",
    "loss_cb = LossMonitor(40)\n",
    "\n",
    "#训练\n",
    "print('--------------------AdaGrad优化器--------------------')\n",
    "print('==========Start Training==========')\n",
    "model.train(epoch=1000,train_dataset=train_dataset, callbacks=[ckpt_cb, loss_cb])\n",
    "\n",
    "# 模型评估\n",
    "Acc=model.eval(test_dataset)\n",
    "print(Acc)\n",
    "\n",
    "# 输出预测结果\n",
    "test_iter = test_dataset.create_dict_iterator()._get_next() # 构造迭代器\n",
    "features = Tensor(test_iter['x'], mindspore.float32) # 构造特征张量\n",
    "predictions = model.predict(features) # 预测结果\n",
    "predictions = predictions.asnumpy() #转换成numpy格式\n",
    "num2label=['Setosa','Versicolor','Virginica']\n",
    "for i in range(30):\n",
    "    sample = predictions[i,:].tolist()\n",
    "    print('第'+str(i)+'个sample预测结果: ',num2label[sample.index(max(sample))],'    真实结果: ', num2label[test_iter['y'][i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
